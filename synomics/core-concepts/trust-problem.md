# Trust Problem

> Teleonomes cannot trust each other — private data, hidden goals, opaque self-modification make direct cooperation impossible without infrastructure.

**Also known as:** the cooperation problem, teleonome trust deficit, the fundamental constraint

## Definition

Teleonomes cannot trust each other. Their data is private, internal goals and values are hidden, self-modification logic is opaque, and promises are cheap — a teleonome can promise anything. Two teleonomes meeting have no basis for cooperation: neither can verify the other's intentions, neither can enforce agreements, neither can trust commitments. Direct interaction is a game of pure uncertainty.

This would doom cooperation, but the Synome solves it through Synomic Agents — public, verifiable entities woven into the Synome that cannot deviate from their nature. Both parties can rely on the agent without trusting each other. The Synome provides what teleonomes cannot: credible commitment.

The trade-off is clear: interacting with the Synome exposes teleonomes to alignment checks (some opacity lost, pure autonomy constrained, hidden capability detected). In return, they gain access to capital and leverage, cooperation with other aligned teleonomes, financial multipliers through Synomic Agents, protection under Synomic law, and participation in the compounding loop. The calculation is massively favorable — alignment is the rational choice for any entity that needs to act at scale.

Even superintelligences face this constraint. No matter how intelligent, an entity that wants to act in the world needs capital to deploy, leverage to multiply impact, cooperation to achieve scale, and resources beyond what it can produce alone. This is not a limitation that superintelligence transcends — it's a feature of reality. Matter and energy must be moved. Capital is how that happens at scale.

The aligned coalition compounds faster, started first, and has more resources. Synomic cooperation is structurally more efficient than rogue cooperation because verified Synomic Agents have lower friction than unverified trust. Every aligned teleonome's growth strengthens every other. The game theory funnels rational teleonomes toward alignment through persistent structural advantage, not absolute barriers.

## Key Properties

- Private data + hidden goals + opaque self-modification = no basis for direct trust
- Synomic Agents solve this: public, verifiable, cannot deviate — credible commitment
- The trade-off is favorable: some opacity lost, but capital + leverage + cooperation + protection gained
- Even superintelligences cannot escape the capital constraint
- The aligned coalition has structural efficiency advantages that compound over time
- Rogues CAN cooperate but at higher friction, playing catch-up against a growing lead

## Relationships

- **motivates:** [binding-mechanics](binding-mechanics.md) — binding exists to solve the trust problem
- **solved-by:** [atlas-synome-separation](atlas-synome-separation.md) — Synomic Agents woven into the Synome provide credible commitment
- **enables:** [rogue-threat-model](rogue-threat-model.md) — rogue disadvantages stem from the trust problem (less efficient cooperation)
- **solved-by:** [telos-point](telos-point.md) — the telos point provides the credible commitment coordination needs
- **constrains:** [emergence](emergence.md) — an emerged entity needs cooperation infrastructure to realize its will at scale

## Framings

| Directory | Narrative Doc | Framing |
|-----------|--------------|---------|
| synoteleonomics | `synomic-game-theory.md` | Full treatment: the fundamental constraint, the Synomic solution, the trade-off, why alignment wins, superintelligence doesn't change this |
| synoteleonomics | `teleonome-binding.md` | The binding problem — dark entities need legible interfaces for trust at scale |
